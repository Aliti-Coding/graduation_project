{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers, callbacks\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lstm_model import load_model_weights_from_checkpoint\n",
    "\n",
    "VOCAB_SIZE = 15000\n",
    "SEQUENCE_LENGTH = 100\n",
    "EMBED_DIM = 24\n",
    "SEED = 0\n",
    "\n",
    "DATA_PATH=r\"../../data/transformed/amazon_reviews_5_partition_1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reader = pd.read_csv(\n",
    "    DATA_PATH,\n",
    "    index_col=0,\n",
    "    chunksize=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_reader.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH, index_col=0)\n",
    "df = df.dropna()\n",
    "\n",
    "df[\"reviewText\"] = df[\"reviewText\"].astype(\"string\")\n",
    "\n",
    "x = df[\"reviewText\"]\n",
    "y = df[\"overall\"] -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../checkpoints/vectorization_vocabulary.txt\", \"r\") as file:\n",
    "    vocab = file.read()\n",
    "    vocab=vocab.split(\"\\n\")[:-1] #last line is an empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = layers.TextVectorization(\n",
    "    VOCAB_SIZE,\n",
    "    \"lower_and_strip_punctuation\",\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=SEQUENCE_LENGTH,\n",
    "    vocabulary=vocab\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase complexity\n",
    "\n",
    "lstm_model = keras.Sequential(\n",
    "        [\n",
    "            layers.Input(shape=(1,), dtype=\"string\"),\n",
    "            vectorize_layer,\n",
    "            layers.Embedding(VOCAB_SIZE, EMBED_DIM),\n",
    "            layers.LSTM(24, dropout=0.5, return_sequences=True),\n",
    "            layers.LSTM(24, dropout=0.5),\n",
    "            layers.Dense(1)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x13a983190f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load from checkpoint\n",
    "\n",
    "lstm_model.load_weights(r\"../../checkpoints/lstm_model_24_24_250k_rows/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(\n",
    "    optimizer=\"adam\", \n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath=\"../../checkpoints/lstm_model_124_16_10k_rows\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True\n",
    "    ),\n",
    "    callbacks.EarlyStopping(\n",
    "        patience=8\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=cbs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.predict([\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_naive = np.full_like(y_train, dtype=\"float32\", fill_value=2.1539134783695926)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_absolute_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mean_absolute_error(y_train, y_train_naive)\u001b[39m.\u001b[39mnumpy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mean_absolute_error' is not defined"
     ]
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_train_naive).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = lstm_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.DataFrame({\n",
    "    \"text\":x,\n",
    "    \"actual\":y,\n",
    "    \"predicted\":predicted.flatten()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(r\"../../saved_models/lstm_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1608/1608 [==============================] - 36s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "x_test_pred =  model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5817508957319908"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, x_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6016878475227962"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, x_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 100)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 24)           360000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100, 24)           4704      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 24)                4704      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 369,433\n",
      "Trainable params: 369,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model_weights_from_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8996c41306a955084732ca4b0ba338895ff13d1921cf86d4d193db4a88f75fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
