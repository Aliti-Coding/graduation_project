{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizerFast, TFDistilBertForSequenceClassification, TFDistilBertModel\n",
    "import numpy as np\n",
    "from tensorflow import Tensor\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, accuracy_score\n",
    "\n",
    "VOCAB_SIZE = 15000\n",
    "SEQUENCE_LENGTH = 100\n",
    "EMBED_DIM = 8\n",
    "SEED = 0\n",
    "\n",
    "DATA_PATH=r\"../../data/transformed/amazon_reviews_5_partition_1.csv\"\n",
    "\n",
    "BERT_MODEL = \"distilbert-base-uncased-finetuned-sst-2-english\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading and instantiating pre-trained model and tokenizer\n",
    "# model = TFDistilBertForSequenceClassification.from_pretrained(BERT_MODEL, num_labels=2)\n",
    "bert_model = TFDistilBertModel.from_pretrained(BERT_MODEL)\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(BERT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model that takes logits from bert as input\n",
    "inputs = keras.Input(shape=((183, 768)),dtype=\"int64\")\n",
    "x = keras.layers.Dense(768, activation=\"relu\")(inputs)\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "\n",
    "regressor_model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data\n",
    "df = pd.read_csv(\n",
    "    DATA_PATH,\n",
    "    index_col=0,\n",
    "    nrows = 100000\n",
    ")\n",
    "df = df.dropna()\n",
    "df[\"reviewText\"] = df[\"reviewText\"].convert_dtypes(convert_string=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating x and y for training\n",
    "x = tokenizer(\n",
    "    df[\"reviewText\"].to_list(),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors=\"tf\"\n",
    ")\n",
    "\n",
    "y = (df[\"overall\"] > 3) * 1\n",
    "\n",
    "x=dict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the bert model, targeting binary predictions\n",
    "# model.compile(\n",
    "#     optimizer=\"adam\", \n",
    "#     loss=\"sparse_categorical_crossentropy\", \n",
    "#     metrics=[\"accuracy\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating inputs for regressor model\n",
    "preds = bert_model.predict(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    preds, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling regressor top-hat model\n",
    "regressor_model.compile(\n",
    "    optimizer=\"adam\", \n",
    "    loss=\"mse\", \n",
    "    metrics=[\"mae\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting regressor models on predictions from bert (Pre-training)\n",
    "regressor_model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=10,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compining models for fine-tuning and predictions\n",
    "combined_model = keras.Sequential(\n",
    "    [\n",
    "        bert_model,\n",
    "        regressor_model\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom optimizer with custom learnign rate\n",
    "optimizer = keras.optimizers.Adam(1e-5)\n",
    "\n",
    "combined_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"\", # fill in filepath (where to save model)\n",
    "        save_best_only=True\n",
    "    ) ,\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        patience=4\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs = 15,\n",
    "    callbacks=cbs\n",
    "\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8996c41306a955084732ca4b0ba338895ff13d1921cf86d4d193db4a88f75fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
