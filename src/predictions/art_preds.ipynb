{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import keras\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import numpy as np\n",
    "from sqlalchemy import TextClause\n",
    "\n",
    "sys.path.insert(1, r\"..\\models\")\n",
    "sys.path.insert(2, r\"..\\etl\")\n",
    "\n",
    "from connect_db import connect_to_grad_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('../../saved_models/2dcnn_32_16_32_250k_rows/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = connect_to_grad_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    query = TextClause(\"select content from news_api\")\n",
    "    content = conn.execute(query).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ready_text_for_pred(text):\n",
    "    processed_text = re.sub(r\" +\", \" \", (re.sub(r\"[^a-zA-Z]\", \" \", text)).lower().strip())\n",
    "    return processed_text\n",
    "\n",
    "def preprocess_article_content(content):\n",
    "    content = content.strip(\"\\n\")\n",
    "\n",
    "    # Remove all special characters except sentence defining punctuation\n",
    "    cleaned_content = re.sub(r\"[^.!?\\w]\", \" \", content)\n",
    "\n",
    "    # Remove multiple spaces\n",
    "    cleaned_content = re.sub(r\"[ ]+\", \" \", cleaned_content)\n",
    "\n",
    "    # Split on sentence punctuation\n",
    "    split_sentences = re.split(r\"[.!?]\", cleaned_content)\n",
    "\n",
    "    \n",
    "    return split_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preds(article_content):\n",
    "    sentences = preprocess_article_content(article_content)\n",
    "    cleaned_sentences = [ready_text_for_pred(x) for x in sentences]\n",
    "    preds = [model.predict([x]) for x in cleaned_sentences]\n",
    "\n",
    "    sentences_w_preds = []\n",
    "    for sentence,pred in zip(sentences, preds):\n",
    "        if pred > 4:\n",
    "            pred = 4\n",
    "        elif pred < 0:\n",
    "            pred = 0\n",
    "        sentences_w_preds.append(sentence + \" \" + str(pred))\n",
    "    \n",
    "    mean_pred = np.mean(preds)\n",
    "    \n",
    "    return \". \".join(sentences_w_preds), mean_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_table(\n",
    "    \"news_api\", \n",
    "    engine.connect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = df[\"content\"].apply(create_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"text_w_preds\", \"mean_pred\"]] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_w_preds = []\n",
    "mean_preds = []\n",
    "for e in preds:\n",
    "    texts_w_preds.append(e[0])\n",
    "    mean_preds.append(e[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mean_preds\"] = mean_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_w_preds\"] = texts_w_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = connect_to_grad_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql(\"news_api_w_preds\", engine, index=True, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8996c41306a955084732ca4b0ba338895ff13d1921cf86d4d193db4a88f75fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
